[
    { "name": "RTX 4060", "vramGb": 8, "recommended": "≤ 8B (Q4/Q5)", "notes": "Good entry GPU; keep context moderate." },
    { "name": "RTX 4070", "vramGb": 12, "recommended": "8B–13B (Q4/Q5)", "notes": "Great for local assistants." },
    { "name": "RTX 4080", "vramGb": 16, "recommended": "13B–34B (Q4)", "notes": "Strong for mid models and SDXL." },
    { "name": "RTX 4090", "vramGb": 24, "recommended": "34B–70B (Q4) / SDXL Pro", "notes": "Best consumer GPU for local AI." },
    { "name": "RTX 6000 Ada", "vramGb": 48, "recommended": "70B+ (Q4/Q5)", "notes": "Workstation-grade; excellent VRAM." },
    { "name": "A100", "vramGb": 80, "recommended": "70B+ / Multi workloads", "notes": "Datacenter GPU; expensive but powerful." },
    { "name": "H100", "vramGb": 80, "recommended": "Large-scale inference", "notes": "Top-tier datacenter GPU." }
  ]