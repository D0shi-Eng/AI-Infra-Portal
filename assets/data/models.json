[
    {
      "id": "gpt-4o",
      "name": "GPT-4o",
      "provider": "OpenAI",
      "type": "LLM",
      "family": "GPT",
      "open": false,
      "moe": false,
      "modalities": ["Multi"],
      "languages": ["AR", "EN"],
      "license": "Commercial",
      "paramsB": null,
      "contextK": null,
      "minVramGb": null,
      "recommendedVramGb": null,
      "minRamGb": null,
      "recommendedRamGb": null,
      "requirementsNote": "Cloud model (API). Hardware requirements depend on provider.",
      "notes": "General-purpose multimodal model."
    },
    {
      "id": "claude-3-opus",
      "name": "Claude 3 Opus",
      "provider": "Anthropic",
      "type": "LLM",
      "family": "Claude",
      "open": false,
      "moe": false,
      "modalities": ["Text"],
      "languages": ["AR", "EN"],
      "license": "Commercial",
      "paramsB": null,
      "contextK": null,
      "notes": "High-end reasoning model (cloud)."
    },
  
    {
      "id": "llama-3-8b",
      "name": "Llama 3 8B",
      "provider": "Meta",
      "type": "LLM",
      "family": "Llama",
      "open": true,
      "moe": false,
      "modalities": ["Text"],
      "languages": ["EN", "AR"],
      "license": "Meta",
      "paramsB": 8,
      "contextK": 8,
      "minVramGb": 6,
      "recommendedVramGb": 10,
      "minRamGb": 16,
      "recommendedRamGb": 24,
      "notes": "Great local model for chat & assistants."
    },
    {
      "id": "llama-3-70b",
      "name": "Llama 3 70B",
      "provider": "Meta",
      "type": "LLM",
      "family": "Llama",
      "open": true,
      "moe": false,
      "modalities": ["Text"],
      "languages": ["EN", "AR"],
      "license": "Meta",
      "paramsB": 70,
      "contextK": 8,
      "minVramGb": 40,
      "recommendedVramGb": 80,
      "minRamGb": 96,
      "recommendedRamGb": 160,
      "notes": "Large model; best with 48â€“80GB VRAM or multi-GPU."
    },
  
    {
      "id": "qwen2-7b",
      "name": "Qwen2 7B",
      "provider": "Alibaba",
      "type": "LLM",
      "family": "Qwen",
      "open": true,
      "moe": false,
      "modalities": ["Text"],
      "languages": ["EN", "AR", "ZH"],
      "license": "Apache-2.0",
      "paramsB": 7,
      "contextK": 32,
      "minVramGb": 6,
      "recommendedVramGb": 10,
      "minRamGb": 16,
      "recommendedRamGb": 24,
      "notes": "Strong general model with long context variants."
    },
    {
      "id": "mixtral-8x7b",
      "name": "Mixtral 8x7B",
      "provider": "Mistral",
      "type": "LLM",
      "family": "Mixtral",
      "open": true,
      "moe": true,
      "modalities": ["Text"],
      "languages": ["EN", "AR"],
      "license": "Apache-2.0",
      "paramsB": 47,
      "contextK": 32,
      "minVramGb": 18,
      "recommendedVramGb": 24,
      "minRamGb": 48,
      "recommendedRamGb": 64,
      "notes": "MoE model; efficient for performance vs cost."
    },
  
    {
      "id": "deepseek-coder-33b",
      "name": "DeepSeek Coder 33B",
      "provider": "DeepSeek",
      "type": "Code LLM",
      "family": "DeepSeek",
      "open": true,
      "moe": false,
      "modalities": ["Text"],
      "languages": ["EN", "AR"],
      "license": "Open",
      "paramsB": 33,
      "contextK": 16,
      "minVramGb": 18,
      "recommendedVramGb": 24,
      "minRamGb": 64,
      "recommendedRamGb": 96,
      "notes": "Strong coding-focused model for local dev."
    },
  
    {
      "id": "whisper-large-v3",
      "name": "Whisper Large v3",
      "provider": "OpenAI",
      "type": "ASR",
      "family": "Whisper",
      "open": true,
      "moe": false,
      "modalities": ["Audio"],
      "languages": ["AR", "EN"],
      "license": "MIT",
      "paramsB": null,
      "contextK": null,
      "minVramGb": 4,
      "recommendedVramGb": 8,
      "minRamGb": 16,
      "recommendedRamGb": 24,
      "notes": "Speech-to-text with strong multilingual support."
    },
  
    {
      "id": "sdxl",
      "name": "Stable Diffusion XL",
      "provider": "Stability AI",
      "type": "Image Gen",
      "family": "SD",
      "open": true,
      "moe": false,
      "modalities": ["Image"],
      "languages": ["EN", "AR"],
      "license": "OpenRAIL",
      "paramsB": null,
      "contextK": null,
      "minVramGb": 8,
      "recommendedVramGb": 12,
      "minRamGb": 16,
      "recommendedRamGb": 32,
      "notes": "Popular image generation model; VRAM depends on resolution."
    }
  ]