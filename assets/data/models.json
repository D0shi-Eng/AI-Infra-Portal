[
  {
    "id": "gpt-4o",
    "name": "GPT-4o",
    "provider": "OpenAI",
    "type": "LLM",
    "family": "GPT",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Flagship multimodal model. Text, vision, audio I/O. Cloud-only via API."
  },
  {
    "id": "gpt-4o-mini",
    "name": "GPT-4o Mini",
    "provider": "OpenAI",
    "type": "LLM",
    "family": "GPT",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Cost-efficient smaller GPT-4o variant. Great for high-volume tasks."
  },
  {
    "id": "gpt-4-turbo",
    "name": "GPT-4 Turbo",
    "provider": "OpenAI",
    "type": "LLM",
    "family": "GPT",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "High-capability model with vision. 128K context. Cloud-only."
  },
  {
    "id": "gpt-3.5-turbo",
    "name": "GPT-3.5 Turbo",
    "provider": "OpenAI",
    "type": "LLM",
    "family": "GPT",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 16,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Fast and affordable. Good for simple tasks and chatbots."
  },
  {
    "id": "o1",
    "name": "o1",
    "provider": "OpenAI",
    "type": "LLM",
    "family": "o-series",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Reasoning-focused model. Excels at math, coding, and complex logic. Cloud-only."
  },
  {
    "id": "o1-mini",
    "name": "o1-mini",
    "provider": "OpenAI",
    "type": "LLM",
    "family": "o-series",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Smaller reasoning model. Good cost/performance for STEM tasks."
  },
  {
    "id": "o1-pro",
    "name": "o1-pro",
    "provider": "OpenAI",
    "type": "LLM",
    "family": "o-series",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Enhanced reasoning with extended compute. Premium tier. Cloud-only."
  },
  {
    "id": "o3",
    "name": "o3",
    "provider": "OpenAI",
    "type": "LLM",
    "family": "o-series",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Next-gen reasoning model. State-of-the-art on benchmarks. Cloud-only."
  },
  {
    "id": "o3-mini",
    "name": "o3-mini",
    "provider": "OpenAI",
    "type": "LLM",
    "family": "o-series",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Efficient reasoning model. Great for coding and math at lower cost."
  },
  {
    "id": "o4-mini",
    "name": "o4-mini",
    "provider": "OpenAI",
    "type": "LLM",
    "family": "o-series",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Latest compact reasoning model with multimodal support. Cloud-only."
  },
  {
    "id": "dall-e-3",
    "name": "DALLÂ·E 3",
    "provider": "OpenAI",
    "type": "Image Gen",
    "family": "DALL-E",
    "open": false,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN", "AR"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": null,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Text-to-image generation. Integrated into ChatGPT. Cloud-only."
  },
  {
    "id": "whisper-large-v3",
    "name": "Whisper Large v3",
    "provider": "OpenAI",
    "type": "ASR",
    "family": "Whisper",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO", "RU", "PT"],
    "license": "MIT",
    "paramsB": 1.5,
    "contextK": null,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 8,
    "recommendedRamGb": 16,
    "notes": "Best open speech-to-text. 99 languages. Excellent Arabic support."
  },
  {
    "id": "whisper-large-v3-turbo",
    "name": "Whisper Large v3 Turbo",
    "provider": "OpenAI",
    "type": "ASR",
    "family": "Whisper",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO"],
    "license": "MIT",
    "paramsB": 0.8,
    "contextK": null,
    "minVramGb": 2,
    "recommendedVramGb": 6,
    "minRamGb": 8,
    "recommendedRamGb": 16,
    "notes": "Faster variant of Whisper Large. Slightly less accurate but 4x faster."
  },
  {
    "id": "whisper-medium",
    "name": "Whisper Medium",
    "provider": "OpenAI",
    "type": "ASR",
    "family": "Whisper",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "MIT",
    "paramsB": 0.77,
    "contextK": null,
    "minVramGb": 3,
    "recommendedVramGb": 6,
    "minRamGb": 8,
    "recommendedRamGb": 16,
    "notes": "Good balance of speed and accuracy for speech recognition."
  },
  {
    "id": "whisper-small",
    "name": "Whisper Small",
    "provider": "OpenAI",
    "type": "ASR",
    "family": "Whisper",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "MIT",
    "paramsB": 0.24,
    "contextK": null,
    "minVramGb": 1.5,
    "recommendedVramGb": 3,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Lightweight ASR model. Suitable for edge devices."
  },
  {
    "id": "whisper-base",
    "name": "Whisper Base",
    "provider": "OpenAI",
    "type": "ASR",
    "family": "Whisper",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN", "AR"],
    "license": "MIT",
    "paramsB": 0.07,
    "contextK": null,
    "minVramGb": 1,
    "recommendedVramGb": 2,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Minimal ASR model for basic transcription needs."
  },
  {
    "id": "whisper-tiny",
    "name": "Whisper Tiny",
    "provider": "OpenAI",
    "type": "ASR",
    "family": "Whisper",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 0.04,
    "contextK": null,
    "minVramGb": 1,
    "recommendedVramGb": 2,
    "minRamGb": 2,
    "recommendedRamGb": 4,
    "notes": "Smallest Whisper. English-best. Ultra low resource."
  },
  {
    "id": "sora",
    "name": "Sora",
    "provider": "OpenAI",
    "type": "Video Gen",
    "family": "Sora",
    "open": false,
    "moe": false,
    "modalities": ["Video"],
    "languages": ["EN"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": null,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Text-to-video generation. Produces realistic videos up to 1min. Cloud-only."
  },
  {
    "id": "openai-embed-3-small",
    "name": "text-embedding-3-small",
    "provider": "OpenAI",
    "type": "Embedding",
    "family": "Embedding",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 8,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Compact embedding model for RAG and search. Cloud-only."
  },
  {
    "id": "openai-embed-3-large",
    "name": "text-embedding-3-large",
    "provider": "OpenAI",
    "type": "Embedding",
    "family": "Embedding",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 8,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "High-quality embedding model for advanced retrieval. Cloud-only."
  },

  {
    "id": "claude-4-opus",
    "name": "Claude 4 Opus",
    "provider": "Anthropic",
    "type": "LLM",
    "family": "Claude",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Top-tier reasoning and analysis. Extended thinking capability. Cloud-only."
  },
  {
    "id": "claude-4-sonnet",
    "name": "Claude 4 Sonnet",
    "provider": "Anthropic",
    "type": "LLM",
    "family": "Claude",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Balanced performance and cost. Great for coding and analysis. Cloud-only."
  },
  {
    "id": "claude-3.5-sonnet",
    "name": "Claude 3.5 Sonnet",
    "provider": "Anthropic",
    "type": "LLM",
    "family": "Claude",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Excellent coding and reasoning. 200K context. Vision support. Cloud-only."
  },
  {
    "id": "claude-3.5-haiku",
    "name": "Claude 3.5 Haiku",
    "provider": "Anthropic",
    "type": "LLM",
    "family": "Claude",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Fast and affordable. Best for high-volume, latency-sensitive tasks."
  },
  {
    "id": "claude-3-opus",
    "name": "Claude 3 Opus",
    "provider": "Anthropic",
    "type": "LLM",
    "family": "Claude",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "High-end reasoning model with vision. 200K context. Cloud-only."
  },
  {
    "id": "claude-3-sonnet",
    "name": "Claude 3 Sonnet",
    "provider": "Anthropic",
    "type": "LLM",
    "family": "Claude",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Balanced Claude 3 variant. Good for general-purpose tasks."
  },
  {
    "id": "claude-3-haiku",
    "name": "Claude 3 Haiku",
    "provider": "Anthropic",
    "type": "LLM",
    "family": "Claude",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 200,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Fastest Claude 3 model. Instant responses for simple tasks."
  },

  {
    "id": "gemini-2.0-flash",
    "name": "Gemini 2.0 Flash",
    "provider": "Google",
    "type": "LLM",
    "family": "Gemini",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO", "HI"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 1000,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Fast multimodal model. Native tool use. 1M context. Cloud-only."
  },
  {
    "id": "gemini-1.5-pro",
    "name": "Gemini 1.5 Pro",
    "provider": "Google",
    "type": "LLM",
    "family": "Gemini",
    "open": false,
    "moe": true,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO", "HI"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 2000,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "2M context window. Processes text, images, video, audio. Cloud-only."
  },
  {
    "id": "gemini-1.5-flash",
    "name": "Gemini 1.5 Flash",
    "provider": "Google",
    "type": "LLM",
    "family": "Gemini",
    "open": false,
    "moe": true,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 1000,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Fast and efficient. 1M context. Great free-tier option. Cloud-only."
  },
  {
    "id": "gemma-2-2b",
    "name": "Gemma 2 2B",
    "provider": "Google",
    "type": "LLM",
    "family": "Gemma",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Gemma",
    "paramsB": 2,
    "contextK": 8,
    "minVramGb": 2,
    "recommendedVramGb": 3,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Tiny but capable. Great for mobile and edge deployment."
  },
  {
    "id": "gemma-2-9b",
    "name": "Gemma 2 9B",
    "provider": "Google",
    "type": "LLM",
    "family": "Gemma",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Gemma",
    "paramsB": 9,
    "contextK": 8,
    "minVramGb": 5,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Strong performance for its size. Knowledge distillation from larger models."
  },
  {
    "id": "gemma-2-27b",
    "name": "Gemma 2 27B",
    "provider": "Google",
    "type": "LLM",
    "family": "Gemma",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Gemma",
    "paramsB": 27,
    "contextK": 8,
    "minVramGb": 16,
    "recommendedVramGb": 24,
    "minRamGb": 32,
    "recommendedRamGb": 48,
    "notes": "Largest Gemma 2. Competitive with larger models."
  },
  {
    "id": "gemma-3-4b",
    "name": "Gemma 3 4B",
    "provider": "Google",
    "type": "LLM",
    "family": "Gemma",
    "open": true,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Gemma",
    "paramsB": 4,
    "contextK": 128,
    "minVramGb": 3,
    "recommendedVramGb": 6,
    "minRamGb": 8,
    "recommendedRamGb": 12,
    "notes": "Multimodal Gemma 3. Vision + text. 128K context."
  },
  {
    "id": "gemma-3-12b",
    "name": "Gemma 3 12B",
    "provider": "Google",
    "type": "LLM",
    "family": "Gemma",
    "open": true,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Gemma",
    "paramsB": 12,
    "contextK": 128,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Mid-size Gemma 3 with vision capabilities and 128K context."
  },
  {
    "id": "gemma-3-27b",
    "name": "Gemma 3 27B",
    "provider": "Google",
    "type": "LLM",
    "family": "Gemma",
    "open": true,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Gemma",
    "paramsB": 27,
    "contextK": 128,
    "minVramGb": 16,
    "recommendedVramGb": 24,
    "minRamGb": 32,
    "recommendedRamGb": 48,
    "notes": "Largest Gemma 3. Strong multimodal reasoning with 128K context."
  },
  {
    "id": "paligemma",
    "name": "PaLiGemma",
    "provider": "Google",
    "type": "Vision LLM",
    "family": "Gemma",
    "open": true,
    "moe": false,
    "modalities": ["Image", "Text"],
    "languages": ["EN"],
    "license": "Gemma",
    "paramsB": 3,
    "contextK": 1,
    "minVramGb": 3,
    "recommendedVramGb": 6,
    "minRamGb": 8,
    "recommendedRamGb": 12,
    "notes": "Vision-language model. Image captioning, VQA, OCR."
  },

  {
    "id": "llama-2-7b",
    "name": "Llama 2 7B",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Meta",
    "paramsB": 7,
    "contextK": 4,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Foundational open LLM. 4K context. Good for fine-tuning."
  },
  {
    "id": "llama-2-13b",
    "name": "Llama 2 13B",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Meta",
    "paramsB": 13,
    "contextK": 4,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Mid-tier Llama 2. Better reasoning than 7B."
  },
  {
    "id": "llama-2-70b",
    "name": "Llama 2 70B",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Meta",
    "paramsB": 70,
    "contextK": 4,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "Largest Llama 2. Strong but requires substantial hardware."
  },
  {
    "id": "llama-3-8b",
    "name": "Llama 3 8B",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Meta",
    "paramsB": 8,
    "contextK": 8,
    "minVramGb": 5,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Major leap over Llama 2. Great for local chat and assistants."
  },
  {
    "id": "llama-3-70b",
    "name": "Llama 3 70B",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Meta",
    "paramsB": 70,
    "contextK": 8,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "Very strong open model. Needs 48-80GB VRAM or multi-GPU."
  },
  {
    "id": "llama-3.1-8b",
    "name": "Llama 3.1 8B",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "DE", "FR", "IT", "PT", "HI", "ES", "TH"],
    "license": "Meta",
    "paramsB": 8,
    "contextK": 128,
    "minVramGb": 5,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "128K context. Multilingual. Tool use support. Great local model."
  },
  {
    "id": "llama-3.1-70b",
    "name": "Llama 3.1 70B",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "DE", "FR", "IT", "PT", "HI", "ES", "TH"],
    "license": "Meta",
    "paramsB": 70,
    "contextK": 128,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "128K context. Competitive with GPT-4 class on many benchmarks."
  },
  {
    "id": "llama-3.1-405b",
    "name": "Llama 3.1 405B",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "DE", "FR", "IT", "PT", "HI", "ES", "TH"],
    "license": "Meta",
    "paramsB": 405,
    "contextK": 128,
    "minVramGb": 200,
    "recommendedVramGb": 400,
    "minRamGb": 512,
    "recommendedRamGb": 800,
    "notes": "Largest open model ever. Needs GPU cluster. 128K context."
  },
  {
    "id": "llama-3.2-1b",
    "name": "Llama 3.2 1B",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "DE", "FR", "IT", "PT", "HI", "ES", "TH"],
    "license": "Meta",
    "paramsB": 1,
    "contextK": 128,
    "minVramGb": 1,
    "recommendedVramGb": 2,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Ultra-lightweight. Runs on mobile and edge devices."
  },
  {
    "id": "llama-3.2-3b",
    "name": "Llama 3.2 3B",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "DE", "FR", "IT", "PT", "HI", "ES", "TH"],
    "license": "Meta",
    "paramsB": 3,
    "contextK": 128,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 8,
    "recommendedRamGb": 12,
    "notes": "Compact model for on-device AI. 128K context."
  },
  {
    "id": "llama-3.2-11b-vision",
    "name": "Llama 3.2 11B Vision",
    "provider": "Meta",
    "type": "Vision LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "DE", "FR", "IT", "PT", "HI", "ES"],
    "license": "Meta",
    "paramsB": 11,
    "contextK": 128,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Multimodal. Image understanding + text generation."
  },
  {
    "id": "llama-3.2-90b-vision",
    "name": "Llama 3.2 90B Vision",
    "provider": "Meta",
    "type": "Vision LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "DE", "FR", "IT", "PT", "HI", "ES"],
    "license": "Meta",
    "paramsB": 90,
    "contextK": 128,
    "minVramGb": 48,
    "recommendedVramGb": 80,
    "minRamGb": 128,
    "recommendedRamGb": 192,
    "notes": "Large multimodal model. Strong vision reasoning. Multi-GPU recommended."
  },
  {
    "id": "llama-3.3-70b",
    "name": "Llama 3.3 70B",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "DE", "FR", "IT", "PT", "HI", "ES", "TH"],
    "license": "Meta",
    "paramsB": 70,
    "contextK": 128,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "Improved 70B with 405B-level quality on many tasks."
  },
  {
    "id": "llama-4-scout",
    "name": "Llama 4 Scout",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": true,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO", "HI"],
    "license": "Meta",
    "paramsB": 109,
    "contextK": 512,
    "minVramGb": 48,
    "recommendedVramGb": 80,
    "minRamGb": 128,
    "recommendedRamGb": 192,
    "notes": "MoE (16 experts, 17B active). 10M effective context. Native multimodal."
  },
  {
    "id": "llama-4-maverick",
    "name": "Llama 4 Maverick",
    "provider": "Meta",
    "type": "LLM",
    "family": "Llama",
    "open": true,
    "moe": true,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO", "HI"],
    "license": "Meta",
    "paramsB": 400,
    "contextK": 1000,
    "minVramGb": 200,
    "recommendedVramGb": 400,
    "minRamGb": 512,
    "recommendedRamGb": 800,
    "notes": "MoE (128 experts, 17B active). 1M context. Frontier-class open model."
  },
  {
    "id": "codellama-7b",
    "name": "Code Llama 7B",
    "provider": "Meta",
    "type": "Code LLM",
    "family": "Code Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Meta",
    "paramsB": 7,
    "contextK": 16,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Code-specialized Llama. Great for code completion and generation."
  },
  {
    "id": "codellama-13b",
    "name": "Code Llama 13B",
    "provider": "Meta",
    "type": "Code LLM",
    "family": "Code Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Meta",
    "paramsB": 13,
    "contextK": 16,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Mid-tier Code Llama. Better reasoning while staying efficient."
  },
  {
    "id": "codellama-34b",
    "name": "Code Llama 34B",
    "provider": "Meta",
    "type": "Code LLM",
    "family": "Code Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Meta",
    "paramsB": 34,
    "contextK": 16,
    "minVramGb": 20,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "Best Code Llama for quality. Needs RTX 4090 or better."
  },
  {
    "id": "codellama-70b",
    "name": "Code Llama 70B",
    "provider": "Meta",
    "type": "Code LLM",
    "family": "Code Llama",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Meta",
    "paramsB": 70,
    "contextK": 4,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "Largest Code Llama. Top-tier code generation. Multi-GPU needed."
  },
  {
    "id": "musicgen-large",
    "name": "MusicGen Large",
    "provider": "Meta",
    "type": "Music Gen",
    "family": "AudioCraft",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 3.3,
    "contextK": null,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Text-to-music generation. High quality instrument synthesis."
  },
  {
    "id": "musicgen-medium",
    "name": "MusicGen Medium",
    "provider": "Meta",
    "type": "Music Gen",
    "family": "AudioCraft",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 1.5,
    "contextK": null,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 8,
    "recommendedRamGb": 16,
    "notes": "Balanced music generation model. Good quality with less hardware."
  },
  {
    "id": "sam-2",
    "name": "Segment Anything 2 (SAM 2)",
    "provider": "Meta",
    "type": "Vision",
    "family": "SAM",
    "open": true,
    "moe": false,
    "modalities": ["Image", "Video"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": null,
    "contextK": null,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 8,
    "recommendedRamGb": 16,
    "notes": "Image & video segmentation. State-of-the-art object detection."
  },

  {
    "id": "mistral-7b-v0.3",
    "name": "Mistral 7B v0.3",
    "provider": "Mistral",
    "type": "LLM",
    "family": "Mistral",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "FR", "DE", "ES", "IT"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 32,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Efficient 7B model. Sliding window attention. Great local starter."
  },
  {
    "id": "mistral-nemo-12b",
    "name": "Mistral Nemo 12B",
    "provider": "Mistral",
    "type": "LLM",
    "family": "Mistral",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "FR", "DE", "ES", "IT", "AR"],
    "license": "Apache-2.0",
    "paramsB": 12,
    "contextK": 128,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Co-developed with NVIDIA. 128K context. Excellent quality for size."
  },
  {
    "id": "mixtral-8x7b",
    "name": "Mixtral 8x7B",
    "provider": "Mistral",
    "type": "LLM",
    "family": "Mixtral",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN", "FR", "DE", "ES", "IT"],
    "license": "Apache-2.0",
    "paramsB": 47,
    "contextK": 32,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "MoE (8 experts, ~12B active). Fast inference with high quality."
  },
  {
    "id": "mixtral-8x22b",
    "name": "Mixtral 8x22B",
    "provider": "Mistral",
    "type": "LLM",
    "family": "Mixtral",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN", "FR", "DE", "ES", "IT"],
    "license": "Apache-2.0",
    "paramsB": 141,
    "contextK": 64,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "Large MoE (~39B active). 64K context. Near-GPT4 class."
  },
  {
    "id": "mistral-small-24b",
    "name": "Mistral Small 24B",
    "provider": "Mistral",
    "type": "LLM",
    "family": "Mistral",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "FR", "DE", "ES", "IT"],
    "license": "Apache-2.0",
    "paramsB": 24,
    "contextK": 32,
    "minVramGb": 14,
    "recommendedVramGb": 20,
    "minRamGb": 32,
    "recommendedRamGb": 48,
    "notes": "Good balance of quality and efficiency. Fits on RTX 4090."
  },
  {
    "id": "mistral-large",
    "name": "Mistral Large",
    "provider": "Mistral",
    "type": "LLM",
    "family": "Mistral",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "FR", "DE", "ES", "IT", "AR", "ZH"],
    "license": "Commercial",
    "paramsB": 123,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Flagship Mistral model. 128K context. Cloud API preferred."
  },
  {
    "id": "codestral-22b",
    "name": "Codestral 22B",
    "provider": "Mistral",
    "type": "Code LLM",
    "family": "Mistral",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "MNPL",
    "paramsB": 22,
    "contextK": 32,
    "minVramGb": 12,
    "recommendedVramGb": 16,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Code-specialized. 80+ programming languages. Fill-in-the-middle support."
  },
  {
    "id": "pixtral-12b",
    "name": "Pixtral 12B",
    "provider": "Mistral",
    "type": "Vision LLM",
    "family": "Mistral",
    "open": true,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "FR", "DE", "ES"],
    "license": "Apache-2.0",
    "paramsB": 12,
    "contextK": 128,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Natively multimodal. Image understanding + text. 128K context."
  },
  {
    "id": "pixtral-large",
    "name": "Pixtral Large 124B",
    "provider": "Mistral",
    "type": "Vision LLM",
    "family": "Mistral",
    "open": true,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "FR", "DE", "ES", "AR"],
    "license": "MNPL",
    "paramsB": 124,
    "contextK": 128,
    "minVramGb": 80,
    "recommendedVramGb": 160,
    "minRamGb": 192,
    "recommendedRamGb": 320,
    "notes": "Frontier-class multimodal. Best-in-class image reasoning. Multi-GPU."
  },

  {
    "id": "qwen2-0.5b",
    "name": "Qwen 2 0.5B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 0.5,
    "contextK": 32,
    "minVramGb": 1,
    "recommendedVramGb": 2,
    "minRamGb": 2,
    "recommendedRamGb": 4,
    "notes": "Tiny model for edge and mobile deployment."
  },
  {
    "id": "qwen2-1.5b",
    "name": "Qwen 2 1.5B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR"],
    "license": "Apache-2.0",
    "paramsB": 1.5,
    "contextK": 32,
    "minVramGb": 1.5,
    "recommendedVramGb": 3,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Small but effective for basic tasks."
  },
  {
    "id": "qwen2-7b",
    "name": "Qwen 2 7B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 32,
    "minVramGb": 4,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Strong general model with good Arabic support."
  },
  {
    "id": "qwen2-72b",
    "name": "Qwen 2 72B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR"],
    "license": "Apache-2.0",
    "paramsB": 72,
    "contextK": 32,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "Top-tier open model. Competitive with Llama 3 70B."
  },
  {
    "id": "qwen2.5-0.5b",
    "name": "Qwen 2.5 0.5B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR"],
    "license": "Apache-2.0",
    "paramsB": 0.5,
    "contextK": 32,
    "minVramGb": 1,
    "recommendedVramGb": 2,
    "minRamGb": 2,
    "recommendedRamGb": 4,
    "notes": "Latest tiny Qwen. Improved training data."
  },
  {
    "id": "qwen2.5-1.5b",
    "name": "Qwen 2.5 1.5B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR"],
    "license": "Apache-2.0",
    "paramsB": 1.5,
    "contextK": 32,
    "minVramGb": 1.5,
    "recommendedVramGb": 3,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Efficient small model for embedded AI use cases."
  },
  {
    "id": "qwen2.5-3b",
    "name": "Qwen 2.5 3B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR"],
    "license": "Apache-2.0",
    "paramsB": 3,
    "contextK": 32,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 8,
    "recommendedRamGb": 12,
    "notes": "Good balance of size and capability for on-device."
  },
  {
    "id": "qwen2.5-7b",
    "name": "Qwen 2.5 7B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR", "FR", "DE", "ES", "JA", "KO"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 128,
    "minVramGb": 4,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "128K context. Excellent multilingual including Arabic."
  },
  {
    "id": "qwen2.5-14b",
    "name": "Qwen 2.5 14B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR", "FR", "DE", "ES", "JA", "KO"],
    "license": "Apache-2.0",
    "paramsB": 14,
    "contextK": 128,
    "minVramGb": 10,
    "recommendedVramGb": 16,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Strong mid-tier model. Great for local deployment."
  },
  {
    "id": "qwen2.5-32b",
    "name": "Qwen 2.5 32B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR", "FR", "DE", "ES", "JA", "KO"],
    "license": "Apache-2.0",
    "paramsB": 32,
    "contextK": 128,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "128K context. Excellent reasoning. Fits RTX 4090 quantized."
  },
  {
    "id": "qwen2.5-72b",
    "name": "Qwen 2.5 72B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR", "FR", "DE", "ES", "JA", "KO"],
    "license": "Apache-2.0",
    "paramsB": 72,
    "contextK": 128,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "Frontier open model. Top MMLU scores. Multi-GPU recommended."
  },
  {
    "id": "qwen2.5-coder-7b",
    "name": "Qwen 2.5 Coder 7B",
    "provider": "Alibaba",
    "type": "Code LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 128,
    "minVramGb": 4,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Code-specialized Qwen. 92 programming languages."
  },
  {
    "id": "qwen2.5-coder-32b",
    "name": "Qwen 2.5 Coder 32B",
    "provider": "Alibaba",
    "type": "Code LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 32,
    "contextK": 128,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "Best open coding model. Competes with GPT-4 on coding benchmarks."
  },
  {
    "id": "qwq-32b",
    "name": "QwQ 32B",
    "provider": "Alibaba",
    "type": "LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR"],
    "license": "Apache-2.0",
    "paramsB": 32,
    "contextK": 32,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "Reasoning model (chain-of-thought). Competes with o1-class models."
  },
  {
    "id": "qwen2-vl-7b",
    "name": "Qwen 2 VL 7B",
    "provider": "Alibaba",
    "type": "Vision LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "ZH", "AR"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 32,
    "minVramGb": 6,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Vision-language model. Image & video understanding."
  },
  {
    "id": "qwen2-vl-72b",
    "name": "Qwen 2 VL 72B",
    "provider": "Alibaba",
    "type": "Vision LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "ZH", "AR"],
    "license": "Apache-2.0",
    "paramsB": 72,
    "contextK": 32,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "Large vision-language model. State-of-the-art VQA. Multi-GPU."
  },
  {
    "id": "qwen2-audio",
    "name": "Qwen 2 Audio",
    "provider": "Alibaba",
    "type": "Audio LLM",
    "family": "Qwen",
    "open": true,
    "moe": false,
    "modalities": ["Audio", "Text"],
    "languages": ["EN", "ZH", "AR"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 32,
    "minVramGb": 6,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Audio understanding and generation. Supports speech + sound analysis."
  },

  {
    "id": "deepseek-v3",
    "name": "DeepSeek V3",
    "provider": "DeepSeek",
    "type": "LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR"],
    "license": "DeepSeek",
    "paramsB": 671,
    "contextK": 128,
    "minVramGb": 80,
    "recommendedVramGb": 160,
    "minRamGb": 256,
    "recommendedRamGb": 512,
    "notes": "MoE (256 experts, 37B active). Top-tier performance. Multi-GPU/cloud."
  },
  {
    "id": "deepseek-v2",
    "name": "DeepSeek V2",
    "provider": "DeepSeek",
    "type": "LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "DeepSeek",
    "paramsB": 236,
    "contextK": 128,
    "minVramGb": 48,
    "recommendedVramGb": 80,
    "minRamGb": 128,
    "recommendedRamGb": 256,
    "notes": "MoE (160 experts, 21B active). Efficient for its size."
  },
  {
    "id": "deepseek-r1",
    "name": "DeepSeek R1",
    "provider": "DeepSeek",
    "type": "LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR"],
    "license": "MIT",
    "paramsB": 671,
    "contextK": 128,
    "minVramGb": 80,
    "recommendedVramGb": 160,
    "minRamGb": 256,
    "recommendedRamGb": 512,
    "notes": "Reasoning model rivaling o1. MoE 671B. Use distilled versions locally."
  },
  {
    "id": "deepseek-r1-distill-qwen-1.5b",
    "name": "DeepSeek R1 Distill Qwen 1.5B",
    "provider": "DeepSeek",
    "type": "LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "MIT",
    "paramsB": 1.5,
    "contextK": 128,
    "minVramGb": 1.5,
    "recommendedVramGb": 3,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Distilled R1 reasoning into tiny Qwen. Good for edge devices."
  },
  {
    "id": "deepseek-r1-distill-qwen-7b",
    "name": "DeepSeek R1 Distill Qwen 7B",
    "provider": "DeepSeek",
    "type": "LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "MIT",
    "paramsB": 7,
    "contextK": 128,
    "minVramGb": 4,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Distilled R1 reasoning. Strong math/code for 7B class."
  },
  {
    "id": "deepseek-r1-distill-qwen-14b",
    "name": "DeepSeek R1 Distill Qwen 14B",
    "provider": "DeepSeek",
    "type": "LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "MIT",
    "paramsB": 14,
    "contextK": 128,
    "minVramGb": 10,
    "recommendedVramGb": 16,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Distilled R1. Excellent reasoning for its size."
  },
  {
    "id": "deepseek-r1-distill-qwen-32b",
    "name": "DeepSeek R1 Distill Qwen 32B",
    "provider": "DeepSeek",
    "type": "LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "MIT",
    "paramsB": 32,
    "contextK": 128,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "Best distilled R1. Top reasoning performance at 32B."
  },
  {
    "id": "deepseek-r1-distill-llama-8b",
    "name": "DeepSeek R1 Distill Llama 8B",
    "provider": "DeepSeek",
    "type": "LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 8,
    "contextK": 128,
    "minVramGb": 5,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "R1 reasoning distilled into Llama 3.1 8B architecture."
  },
  {
    "id": "deepseek-r1-distill-llama-70b",
    "name": "DeepSeek R1 Distill Llama 70B",
    "provider": "DeepSeek",
    "type": "LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 70,
    "contextK": 128,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "R1 reasoning distilled into Llama 70B. Very strong."
  },
  {
    "id": "deepseek-coder-v2-16b",
    "name": "DeepSeek Coder V2 16B",
    "provider": "DeepSeek",
    "type": "Code LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "DeepSeek",
    "paramsB": 16,
    "contextK": 128,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "MoE code model. 128K context. 338 programming languages."
  },
  {
    "id": "deepseek-coder-v2-236b",
    "name": "DeepSeek Coder V2 236B",
    "provider": "DeepSeek",
    "type": "Code LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "DeepSeek",
    "paramsB": 236,
    "contextK": 128,
    "minVramGb": 48,
    "recommendedVramGb": 80,
    "minRamGb": 128,
    "recommendedRamGb": 256,
    "notes": "Largest code model. MoE 236B. GPT-4 level coding. Multi-GPU."
  },
  {
    "id": "deepseek-coder-6.7b",
    "name": "DeepSeek Coder 6.7B",
    "provider": "DeepSeek",
    "type": "Code LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Open",
    "paramsB": 6.7,
    "contextK": 16,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Strong code model for its size. Project-level code completion."
  },
  {
    "id": "deepseek-coder-33b",
    "name": "DeepSeek Coder 33B",
    "provider": "DeepSeek",
    "type": "Code LLM",
    "family": "DeepSeek",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Open",
    "paramsB": 33,
    "contextK": 16,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 64,
    "recommendedRamGb": 96,
    "notes": "Strong coding-focused model for local development."
  },

  {
    "id": "phi-2",
    "name": "Phi-2 2.7B",
    "provider": "Microsoft",
    "type": "LLM",
    "family": "Phi",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 2.7,
    "contextK": 2,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Surprisingly capable tiny model. Good for research."
  },
  {
    "id": "phi-3-mini",
    "name": "Phi-3 Mini 3.8B",
    "provider": "Microsoft",
    "type": "LLM",
    "family": "Phi",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 3.8,
    "contextK": 128,
    "minVramGb": 3,
    "recommendedVramGb": 6,
    "minRamGb": 8,
    "recommendedRamGb": 12,
    "notes": "Small but punches above its weight. 128K context option."
  },
  {
    "id": "phi-3-small",
    "name": "Phi-3 Small 7B",
    "provider": "Microsoft",
    "type": "LLM",
    "family": "Phi",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 7,
    "contextK": 128,
    "minVramGb": 4,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Strong 7B-class model with 128K context."
  },
  {
    "id": "phi-3-medium",
    "name": "Phi-3 Medium 14B",
    "provider": "Microsoft",
    "type": "LLM",
    "family": "Phi",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 14,
    "contextK": 128,
    "minVramGb": 10,
    "recommendedVramGb": 16,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Mid-size Phi 3. Great quality/size ratio."
  },
  {
    "id": "phi-3.5-mini",
    "name": "Phi-3.5 Mini 3.8B",
    "provider": "Microsoft",
    "type": "LLM",
    "family": "Phi",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "MIT",
    "paramsB": 3.8,
    "contextK": 128,
    "minVramGb": 3,
    "recommendedVramGb": 6,
    "minRamGb": 8,
    "recommendedRamGb": 12,
    "notes": "Improved multilingual Phi. Supports Arabic. 128K context."
  },
  {
    "id": "phi-3.5-moe",
    "name": "Phi-3.5 MoE",
    "provider": "Microsoft",
    "type": "LLM",
    "family": "Phi",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "MIT",
    "paramsB": 42,
    "contextK": 128,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "MoE Phi. 16 experts, 6.6B active. Good quality at low cost."
  },
  {
    "id": "phi-4",
    "name": "Phi-4 14B",
    "provider": "Microsoft",
    "type": "LLM",
    "family": "Phi",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 14,
    "contextK": 16,
    "minVramGb": 10,
    "recommendedVramGb": 16,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Excels at STEM reasoning. Trained with synthetic data."
  },
  {
    "id": "florence-2",
    "name": "Florence-2",
    "provider": "Microsoft",
    "type": "Vision",
    "family": "Florence",
    "open": true,
    "moe": false,
    "modalities": ["Image", "Text"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 0.77,
    "contextK": null,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Unified vision model. Captioning, detection, segmentation, OCR."
  },

  {
    "id": "sd-1.5",
    "name": "Stable Diffusion 1.5",
    "provider": "Stability AI",
    "type": "Image Gen",
    "family": "SD",
    "open": true,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN"],
    "license": "OpenRAIL",
    "paramsB": 0.9,
    "contextK": null,
    "minVramGb": 4,
    "recommendedVramGb": 6,
    "minRamGb": 8,
    "recommendedRamGb": 16,
    "notes": "Classic image generation. Huge ecosystem of fine-tunes & LoRAs."
  },
  {
    "id": "sd-2.1",
    "name": "Stable Diffusion 2.1",
    "provider": "Stability AI",
    "type": "Image Gen",
    "family": "SD",
    "open": true,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN"],
    "license": "OpenRAIL",
    "paramsB": 0.9,
    "contextK": null,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 8,
    "recommendedRamGb": 16,
    "notes": "Improved SD. Better at higher resolutions. Good LoRA ecosystem."
  },
  {
    "id": "sdxl",
    "name": "Stable Diffusion XL",
    "provider": "Stability AI",
    "type": "Image Gen",
    "family": "SD",
    "open": true,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN"],
    "license": "OpenRAIL",
    "paramsB": 6.6,
    "contextK": null,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 16,
    "recommendedRamGb": 32,
    "notes": "1024px native. Great quality. Massive community ecosystem."
  },
  {
    "id": "sd3",
    "name": "Stable Diffusion 3",
    "provider": "Stability AI",
    "type": "Image Gen",
    "family": "SD",
    "open": true,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN"],
    "license": "Stability Community",
    "paramsB": 2,
    "contextK": null,
    "minVramGb": 6,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "MMDiT architecture. Better text rendering and composition."
  },
  {
    "id": "sd3.5-large",
    "name": "Stable Diffusion 3.5 Large",
    "provider": "Stability AI",
    "type": "Image Gen",
    "family": "SD",
    "open": true,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN"],
    "license": "Stability Community",
    "paramsB": 8,
    "contextK": null,
    "minVramGb": 12,
    "recommendedVramGb": 16,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Latest SD. Superior quality and prompt following."
  },
  {
    "id": "sd3.5-medium",
    "name": "Stable Diffusion 3.5 Medium",
    "provider": "Stability AI",
    "type": "Image Gen",
    "family": "SD",
    "open": true,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN"],
    "license": "Stability Community",
    "paramsB": 2.6,
    "contextK": null,
    "minVramGb": 6,
    "recommendedVramGb": 10,
    "minRamGb": 12,
    "recommendedRamGb": 24,
    "notes": "Balanced SD 3.5. Good quality with less VRAM."
  },
  {
    "id": "svd",
    "name": "Stable Video Diffusion",
    "provider": "Stability AI",
    "type": "Video Gen",
    "family": "SD",
    "open": true,
    "moe": false,
    "modalities": ["Video"],
    "languages": ["EN"],
    "license": "Stability Community",
    "paramsB": null,
    "contextK": null,
    "minVramGb": 12,
    "recommendedVramGb": 24,
    "minRamGb": 32,
    "recommendedRamGb": 48,
    "notes": "Image-to-video. 14-25 frames. Needs RTX 4090 for smooth use."
  },
  {
    "id": "stablecode-3b",
    "name": "StableCode 3B",
    "provider": "Stability AI",
    "type": "Code LLM",
    "family": "StableCode",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Stability Community",
    "paramsB": 3,
    "contextK": 16,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 8,
    "recommendedRamGb": 12,
    "notes": "Lightweight code model. Good for autocomplete."
  },
  {
    "id": "stable-audio",
    "name": "Stable Audio Open",
    "provider": "Stability AI",
    "type": "Music Gen",
    "family": "Stable Audio",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN"],
    "license": "Stability Community",
    "paramsB": null,
    "contextK": null,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 8,
    "recommendedRamGb": 16,
    "notes": "Text-to-audio generation. Music and sound effects."
  },

  {
    "id": "flux1-dev",
    "name": "FLUX.1 Dev",
    "provider": "Black Forest Labs",
    "type": "Image Gen",
    "family": "FLUX",
    "open": true,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN"],
    "license": "FLUX.1-dev",
    "paramsB": 12,
    "contextK": null,
    "minVramGb": 12,
    "recommendedVramGb": 24,
    "minRamGb": 24,
    "recommendedRamGb": 48,
    "notes": "State-of-the-art image gen. Best prompt adherence. Guidance distilled."
  },
  {
    "id": "flux1-schnell",
    "name": "FLUX.1 Schnell",
    "provider": "Black Forest Labs",
    "type": "Image Gen",
    "family": "FLUX",
    "open": true,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 12,
    "contextK": null,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 16,
    "recommendedRamGb": 32,
    "notes": "4-step fast generation. Apache-2.0 licensed. Great for production."
  },
  {
    "id": "flux1-pro",
    "name": "FLUX.1 Pro",
    "provider": "Black Forest Labs",
    "type": "Image Gen",
    "family": "FLUX",
    "open": false,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": null,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Highest quality FLUX. Cloud API only."
  },

  {
    "id": "yi-6b",
    "name": "Yi 6B",
    "provider": "01.AI",
    "type": "LLM",
    "family": "Yi",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 6,
    "contextK": 4,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 12,
    "recommendedRamGb": 16,
    "notes": "Bilingual EN/ZH model from 01.AI."
  },
  {
    "id": "yi-34b",
    "name": "Yi 34B",
    "provider": "01.AI",
    "type": "LLM",
    "family": "Yi",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 34,
    "contextK": 4,
    "minVramGb": 20,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "Strong bilingual model. Top scores at 34B size."
  },
  {
    "id": "yi-1.5-9b",
    "name": "Yi 1.5 9B",
    "provider": "01.AI",
    "type": "LLM",
    "family": "Yi",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 9,
    "contextK": 4,
    "minVramGb": 5,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Improved Yi. Better math and reasoning."
  },
  {
    "id": "yi-1.5-34b",
    "name": "Yi 1.5 34B",
    "provider": "01.AI",
    "type": "LLM",
    "family": "Yi",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 34,
    "contextK": 4,
    "minVramGb": 20,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "Enhanced 34B with improved coding and math."
  },

  {
    "id": "grok-1",
    "name": "Grok-1",
    "provider": "xAI",
    "type": "LLM",
    "family": "Grok",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 314,
    "contextK": 8,
    "minVramGb": 80,
    "recommendedVramGb": 160,
    "minRamGb": 256,
    "recommendedRamGb": 512,
    "notes": "Open MoE 314B (8 experts). Requires multi-GPU cluster."
  },
  {
    "id": "grok-2",
    "name": "Grok-2",
    "provider": "xAI",
    "type": "LLM",
    "family": "Grok",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Frontier model with real-time knowledge. Available on X/Twitter."
  },
  {
    "id": "grok-3",
    "name": "Grok-3",
    "provider": "xAI",
    "type": "LLM",
    "family": "Grok",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Latest Grok generation. Advanced reasoning and analysis. Cloud-only."
  },

  {
    "id": "command-r-35b",
    "name": "Command R 35B",
    "provider": "Cohere",
    "type": "LLM",
    "family": "Command",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA"],
    "license": "CC-BY-NC",
    "paramsB": 35,
    "contextK": 128,
    "minVramGb": 20,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "RAG-optimized. 128K context. 10 languages. Tool use support."
  },
  {
    "id": "command-r-plus-104b",
    "name": "Command R+ 104B",
    "provider": "Cohere",
    "type": "LLM",
    "family": "Command",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA"],
    "license": "CC-BY-NC",
    "paramsB": 104,
    "contextK": 128,
    "minVramGb": 80,
    "recommendedVramGb": 160,
    "minRamGb": 192,
    "recommendedRamGb": 256,
    "notes": "Large multilingual model. Excellent RAG and enterprise use. Arabic strong."
  },
  {
    "id": "aya-23-8b",
    "name": "Aya 23 8B",
    "provider": "Cohere",
    "type": "LLM",
    "family": "Aya",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO", "HI", "TR"],
    "license": "Apache-2.0",
    "paramsB": 8,
    "contextK": 8,
    "minVramGb": 5,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Multilingual model covering 23 languages. Excellent Arabic."
  },
  {
    "id": "aya-23-35b",
    "name": "Aya 23 35B",
    "provider": "Cohere",
    "type": "LLM",
    "family": "Aya",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO", "HI", "TR"],
    "license": "Apache-2.0",
    "paramsB": 35,
    "contextK": 8,
    "minVramGb": 20,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "Large multilingual Aya. Covers 23 languages with good quality."
  },
  {
    "id": "aya-expanse-8b",
    "name": "Aya Expanse 8B",
    "provider": "Cohere",
    "type": "LLM",
    "family": "Aya",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO", "HI", "TR"],
    "license": "Apache-2.0",
    "paramsB": 8,
    "contextK": 8,
    "minVramGb": 5,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Latest multilingual model. 23 languages. Improved over Aya 23."
  },
  {
    "id": "aya-expanse-32b",
    "name": "Aya Expanse 32B",
    "provider": "Cohere",
    "type": "LLM",
    "family": "Aya",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO", "HI", "TR"],
    "license": "Apache-2.0",
    "paramsB": 32,
    "contextK": 8,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "Best open multilingual model. 23 languages with excellent Arabic."
  },
  {
    "id": "cohere-embed-v3",
    "name": "Cohere Embed v3",
    "provider": "Cohere",
    "type": "Embedding",
    "family": "Embed",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 0.5,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Multilingual embedding. 100+ languages. Cloud API."
  },

  {
    "id": "nemotron-70b",
    "name": "Nemotron 70B",
    "provider": "NVIDIA",
    "type": "LLM",
    "family": "Nemotron",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "NVIDIA",
    "paramsB": 70,
    "contextK": 32,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "RLHF-aligned by NVIDIA. Strong instruction following."
  },

  {
    "id": "dbrx",
    "name": "DBRX 132B",
    "provider": "Databricks",
    "type": "LLM",
    "family": "DBRX",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Databricks Open",
    "paramsB": 132,
    "contextK": 32,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "MoE 132B (36B active). Efficient inference. Strong general model."
  },

  {
    "id": "arctic",
    "name": "Arctic",
    "provider": "Snowflake",
    "type": "LLM",
    "family": "Arctic",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 480,
    "contextK": 4,
    "minVramGb": 80,
    "recommendedVramGb": 160,
    "minRamGb": 256,
    "recommendedRamGb": 512,
    "notes": "Dense-MoE hybrid. 480B total, 17B active. Enterprise-focused."
  },

  {
    "id": "openelm-1.1b",
    "name": "OpenELM 1.1B",
    "provider": "Apple",
    "type": "LLM",
    "family": "OpenELM",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Apple",
    "paramsB": 1.1,
    "contextK": 2,
    "minVramGb": 1,
    "recommendedVramGb": 2,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Apple's open model. Layer-wise scaling. Efficient for on-device."
  },
  {
    "id": "openelm-3b",
    "name": "OpenELM 3B",
    "provider": "Apple",
    "type": "LLM",
    "family": "OpenELM",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Apple",
    "paramsB": 3,
    "contextK": 2,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 8,
    "recommendedRamGb": 12,
    "notes": "Largest OpenELM. Research-focused with full training recipe."
  },

  {
    "id": "falcon-7b",
    "name": "Falcon 7B",
    "provider": "TII",
    "type": "LLM",
    "family": "Falcon",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "FR", "DE", "ES"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 2,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "From UAE's TII. Trained on RefinedWeb. Good multilingual."
  },
  {
    "id": "falcon-40b",
    "name": "Falcon 40B",
    "provider": "TII",
    "type": "LLM",
    "family": "Falcon",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "FR", "DE", "ES"],
    "license": "Apache-2.0",
    "paramsB": 40,
    "contextK": 2,
    "minVramGb": 22,
    "recommendedVramGb": 48,
    "minRamGb": 64,
    "recommendedRamGb": 96,
    "notes": "Strong 40B model. Multi-query attention for fast inference."
  },
  {
    "id": "falcon-180b",
    "name": "Falcon 180B",
    "provider": "TII",
    "type": "LLM",
    "family": "Falcon",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "FR", "DE", "ES"],
    "license": "Falcon-180B TII",
    "paramsB": 180,
    "contextK": 2,
    "minVramGb": 80,
    "recommendedVramGb": 160,
    "minRamGb": 256,
    "recommendedRamGb": 400,
    "notes": "Largest dense Falcon. Was #1 on LMSYS at launch."
  },
  {
    "id": "falcon-2-11b",
    "name": "Falcon 2 11B",
    "provider": "TII",
    "type": "LLM",
    "family": "Falcon",
    "open": true,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "FR", "DE", "ES"],
    "license": "Apache-2.0",
    "paramsB": 11,
    "contextK": 8,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Multimodal Falcon 2. Vision + text. Strong Arabic."
  },
  {
    "id": "falcon-3-1b",
    "name": "Falcon 3 1B",
    "provider": "TII",
    "type": "LLM",
    "family": "Falcon",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "FR", "DE", "ES"],
    "license": "Apache-2.0",
    "paramsB": 1,
    "contextK": 32,
    "minVramGb": 1,
    "recommendedVramGb": 2,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Tiny Falcon 3. Edge-focused AI from UAE."
  },
  {
    "id": "falcon-3-3b",
    "name": "Falcon 3 3B",
    "provider": "TII",
    "type": "LLM",
    "family": "Falcon",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "FR", "DE", "ES"],
    "license": "Apache-2.0",
    "paramsB": 3,
    "contextK": 32,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 8,
    "recommendedRamGb": 12,
    "notes": "Compact Falcon 3 with improved architecture."
  },
  {
    "id": "falcon-3-7b",
    "name": "Falcon 3 7B",
    "provider": "TII",
    "type": "LLM",
    "family": "Falcon",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "FR", "DE", "ES"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 32,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Latest 7B from TII. Strong multilingual with Arabic support."
  },
  {
    "id": "falcon-3-10b",
    "name": "Falcon 3 10B",
    "provider": "TII",
    "type": "LLM",
    "family": "Falcon",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "FR", "DE", "ES"],
    "license": "Apache-2.0",
    "paramsB": 10,
    "contextK": 32,
    "minVramGb": 6,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Largest Falcon 3. Best quality in the Falcon 3 family."
  },

  {
    "id": "bloom-176b",
    "name": "BLOOM 176B",
    "provider": "BigScience",
    "type": "LLM",
    "family": "BLOOM",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "ES", "PT", "HI"],
    "license": "RAIL",
    "paramsB": 176,
    "contextK": 2,
    "minVramGb": 80,
    "recommendedVramGb": 160,
    "minRamGb": 256,
    "recommendedRamGb": 400,
    "notes": "46 languages + 13 programming languages. First large multilingual open LLM."
  },
  {
    "id": "bloomz-7b",
    "name": "BLOOMZ 7B",
    "provider": "BigScience",
    "type": "LLM",
    "family": "BLOOM",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "ES", "PT", "HI"],
    "license": "RAIL",
    "paramsB": 7,
    "contextK": 2,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Instruction-tuned BLOOM. Great multilingual including Arabic."
  },

  {
    "id": "starcoder-15b",
    "name": "StarCoder 15B",
    "provider": "BigCode",
    "type": "Code LLM",
    "family": "StarCoder",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "OpenRAIL-M",
    "paramsB": 15,
    "contextK": 8,
    "minVramGb": 10,
    "recommendedVramGb": 16,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Trained on The Stack. 80+ programming languages. Fill-in-the-middle."
  },
  {
    "id": "starcoder2-3b",
    "name": "StarCoder2 3B",
    "provider": "BigCode",
    "type": "Code LLM",
    "family": "StarCoder",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "OpenRAIL-M",
    "paramsB": 3,
    "contextK": 16,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 8,
    "recommendedRamGb": 12,
    "notes": "Compact code model. Great for autocomplete on low-end hardware."
  },
  {
    "id": "starcoder2-7b",
    "name": "StarCoder2 7B",
    "provider": "BigCode",
    "type": "Code LLM",
    "family": "StarCoder",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "OpenRAIL-M",
    "paramsB": 7,
    "contextK": 16,
    "minVramGb": 4,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Improved code generation with better training data."
  },
  {
    "id": "starcoder2-15b",
    "name": "StarCoder2 15B",
    "provider": "BigCode",
    "type": "Code LLM",
    "family": "StarCoder",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "OpenRAIL-M",
    "paramsB": 15,
    "contextK": 16,
    "minVramGb": 10,
    "recommendedVramGb": 16,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Best StarCoder2. 600+ languages from The Stack v2."
  },

  {
    "id": "jamba-1.5-mini",
    "name": "Jamba 1.5 Mini",
    "provider": "AI21 Labs",
    "type": "LLM",
    "family": "Jamba",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN", "FR", "DE", "ES"],
    "license": "AI21 Jamba",
    "paramsB": 52,
    "contextK": 256,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "SSM-Transformer hybrid (Mamba). 256K context. Efficient for long docs."
  },
  {
    "id": "jamba-1.5-large",
    "name": "Jamba 1.5 Large",
    "provider": "AI21 Labs",
    "type": "LLM",
    "family": "Jamba",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN", "FR", "DE", "ES", "PT"],
    "license": "AI21 Jamba",
    "paramsB": 398,
    "contextK": 256,
    "minVramGb": 80,
    "recommendedVramGb": 160,
    "minRamGb": 256,
    "recommendedRamGb": 512,
    "notes": "Large Mamba-Transformer MoE. 256K context. Multi-GPU required."
  },

  {
    "id": "llava-1.5-7b",
    "name": "LLaVA 1.5 7B",
    "provider": "LLaVA Team",
    "type": "Vision LLM",
    "family": "LLaVA",
    "open": true,
    "moe": false,
    "modalities": ["Image", "Text"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 4,
    "minVramGb": 6,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Open vision-language model. Image Q&A and captioning."
  },
  {
    "id": "llava-1.5-13b",
    "name": "LLaVA 1.5 13B",
    "provider": "LLaVA Team",
    "type": "Vision LLM",
    "family": "LLaVA",
    "open": true,
    "moe": false,
    "modalities": ["Image", "Text"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 13,
    "contextK": 4,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Better quality image understanding than 7B variant."
  },
  {
    "id": "llava-1.6-34b",
    "name": "LLaVA 1.6 34B",
    "provider": "LLaVA Team",
    "type": "Vision LLM",
    "family": "LLaVA",
    "open": true,
    "moe": false,
    "modalities": ["Image", "Text"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 34,
    "contextK": 4,
    "minVramGb": 20,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "High-resolution image understanding. Dynamic resolution."
  },

  {
    "id": "internlm2-7b",
    "name": "InternLM2 7B",
    "provider": "Shanghai AI Lab",
    "type": "LLM",
    "family": "InternLM",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 32,
    "minVramGb": 4,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Strong bilingual model from Shanghai AI Lab."
  },
  {
    "id": "internlm2-20b",
    "name": "InternLM2 20B",
    "provider": "Shanghai AI Lab",
    "type": "LLM",
    "family": "InternLM",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 20,
    "contextK": 32,
    "minVramGb": 12,
    "recommendedVramGb": 20,
    "minRamGb": 32,
    "recommendedRamGb": 48,
    "notes": "Top-performing 20B model. Excellent math and reasoning."
  },
  {
    "id": "internvl2",
    "name": "InternVL2",
    "provider": "Shanghai AI Lab",
    "type": "Vision LLM",
    "family": "InternVL",
    "open": true,
    "moe": false,
    "modalities": ["Image", "Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 26,
    "contextK": 32,
    "minVramGb": 16,
    "recommendedVramGb": 24,
    "minRamGb": 32,
    "recommendedRamGb": 48,
    "notes": "Open vision-language model rivaling GPT-4V on benchmarks."
  },

  {
    "id": "rwkv-6-world-7b",
    "name": "RWKV-6 World 7B",
    "provider": "RWKV Foundation",
    "type": "LLM",
    "family": "RWKV",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR", "JA"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 32,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "RNN architecture. Linear complexity. Infinite context potential."
  },
  {
    "id": "rwkv-6-world-14b",
    "name": "RWKV-6 World 14B",
    "provider": "RWKV Foundation",
    "type": "LLM",
    "family": "RWKV",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR", "JA"],
    "license": "Apache-2.0",
    "paramsB": 14,
    "contextK": 32,
    "minVramGb": 10,
    "recommendedVramGb": 16,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Larger RWKV with RNN efficiency. Constant memory for any length."
  },

  {
    "id": "solar-10.7b",
    "name": "Solar 10.7B",
    "provider": "Upstage",
    "type": "LLM",
    "family": "Solar",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "KO"],
    "license": "Apache-2.0",
    "paramsB": 10.7,
    "contextK": 4,
    "minVramGb": 6,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Depth Up-Scaled architecture. Strong for its size. Korean focused."
  },

  {
    "id": "olmo-2-7b",
    "name": "OLMo 2 7B",
    "provider": "Allen AI",
    "type": "LLM",
    "family": "OLMo",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 4,
    "minVramGb": 4,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Fully open (data + code + weights). Research-grade transparency."
  },
  {
    "id": "olmo-2-13b",
    "name": "OLMo 2 13B",
    "provider": "Allen AI",
    "type": "LLM",
    "family": "OLMo",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 13,
    "contextK": 4,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Fully open model. Complete training pipeline published."
  },
  {
    "id": "tulu-3",
    "name": "TÃ¼lu 3 70B",
    "provider": "Allen AI",
    "type": "LLM",
    "family": "TÃ¼lu",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 70,
    "contextK": 128,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "Fine-tuned Llama 3.1 with DPO. Open post-training recipe."
  },

  {
    "id": "chatglm3-6b",
    "name": "ChatGLM3 6B",
    "provider": "Zhipu AI",
    "type": "LLM",
    "family": "GLM",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 6,
    "contextK": 32,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 12,
    "recommendedRamGb": 16,
    "notes": "Bilingual EN/ZH chat model. Good for Chinese NLP tasks."
  },
  {
    "id": "glm-4",
    "name": "GLM-4",
    "provider": "Zhipu AI",
    "type": "LLM",
    "family": "GLM",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "ZH"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Frontier Chinese LLM. Multimodal. Cloud-only."
  },

  {
    "id": "baichuan2-7b",
    "name": "Baichuan2 7B",
    "provider": "Baichuan",
    "type": "LLM",
    "family": "Baichuan",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 4,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Chinese-focused LLM. Good for ZH NLP tasks."
  },
  {
    "id": "baichuan2-13b",
    "name": "Baichuan2 13B",
    "provider": "Baichuan",
    "type": "LLM",
    "family": "Baichuan",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 13,
    "contextK": 4,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Larger Baichuan. Strong bilingual understanding."
  },

  {
    "id": "moondream-2b",
    "name": "Moondream 2B",
    "provider": "Vikhyat",
    "type": "Vision LLM",
    "family": "Moondream",
    "open": true,
    "moe": false,
    "modalities": ["Image", "Text"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 2,
    "contextK": 2,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Tiny vision model. Runs on edge devices. Image Q&A."
  },

  {
    "id": "cogvlm2",
    "name": "CogVLM2",
    "provider": "Zhipu AI",
    "type": "Vision LLM",
    "family": "CogVLM",
    "open": true,
    "moe": false,
    "modalities": ["Image", "Text"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": 19,
    "contextK": 8,
    "minVramGb": 12,
    "recommendedVramGb": 20,
    "minRamGb": 32,
    "recommendedRamGb": 48,
    "notes": "Strong vision-language model. OCR, VQA, image understanding."
  },

  {
    "id": "fuyu-8b",
    "name": "Fuyu 8B",
    "provider": "Adept",
    "type": "Vision LLM",
    "family": "Fuyu",
    "open": true,
    "moe": false,
    "modalities": ["Image", "Text"],
    "languages": ["EN"],
    "license": "CC-BY-NC",
    "paramsB": 8,
    "contextK": 16,
    "minVramGb": 6,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Novel architecture â raw image patches directly. No vision encoder."
  },

  {
    "id": "bark",
    "name": "Bark",
    "provider": "Suno",
    "type": "TTS",
    "family": "Bark",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO", "RU"],
    "license": "MIT",
    "paramsB": null,
    "contextK": null,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 8,
    "recommendedRamGb": 16,
    "notes": "Text-to-speech + music + sound effects. Multilingual. Very expressive."
  },

  {
    "id": "xtts-v2",
    "name": "XTTS v2",
    "provider": "Coqui",
    "type": "TTS",
    "family": "XTTS",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO"],
    "license": "MPL-2.0",
    "paramsB": null,
    "contextK": null,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Voice cloning with 6-second sample. 17 languages. Low latency."
  },

  {
    "id": "tortoise-tts",
    "name": "Tortoise TTS",
    "provider": "James Betker",
    "type": "TTS",
    "family": "Tortoise",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": null,
    "contextK": null,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 8,
    "recommendedRamGb": 16,
    "notes": "High quality text-to-speech. Slow but very natural sounding."
  },

  {
    "id": "parler-tts",
    "name": "Parler TTS",
    "provider": "Hugging Face",
    "type": "TTS",
    "family": "Parler",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 0.88,
    "contextK": null,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Describe the voice style in text. Fast and natural TTS."
  },

  {
    "id": "f5-tts",
    "name": "F5-TTS",
    "provider": "SWivid",
    "type": "TTS",
    "family": "F5",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN", "ZH"],
    "license": "MIT",
    "paramsB": null,
    "contextK": null,
    "minVramGb": 2,
    "recommendedVramGb": 4,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Flow-matching TTS. Zero-shot voice cloning. Very fast."
  },

  {
    "id": "dia-1.6b",
    "name": "Dia 1.6B",
    "provider": "Nari Labs",
    "type": "TTS",
    "family": "Dia",
    "open": true,
    "moe": false,
    "modalities": ["Audio"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 1.6,
    "contextK": null,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 8,
    "recommendedRamGb": 16,
    "notes": "Multi-speaker dialogue TTS with emotions. Generates realistic conversations."
  },

  {
    "id": "bge-large",
    "name": "BGE-Large-EN v1.5",
    "provider": "BAAI",
    "type": "Embedding",
    "family": "BGE",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "MIT",
    "paramsB": 0.33,
    "contextK": 0.5,
    "minVramGb": 1,
    "recommendedVramGb": 2,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Top embedding model for RAG. Fast and accurate retrieval."
  },
  {
    "id": "bge-m3",
    "name": "BGE-M3",
    "provider": "BAAI",
    "type": "Embedding",
    "family": "BGE",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA", "KO"],
    "license": "MIT",
    "paramsB": 0.57,
    "contextK": 8,
    "minVramGb": 1,
    "recommendedVramGb": 2,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Multi-lingual, multi-functionality, multi-granularity embeddings."
  },
  {
    "id": "e5-mistral-7b",
    "name": "E5 Mistral 7B",
    "provider": "Microsoft",
    "type": "Embedding",
    "family": "E5",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "MIT",
    "paramsB": 7,
    "contextK": 4,
    "minVramGb": 4,
    "recommendedVramGb": 8,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "LLM-based embedding. Strongest open embedding at its release."
  },
  {
    "id": "gte-qwen2",
    "name": "GTE-Qwen2 7B",
    "provider": "Alibaba",
    "type": "Embedding",
    "family": "GTE",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH", "AR"],
    "license": "Apache-2.0",
    "paramsB": 7,
    "contextK": 32,
    "minVramGb": 4,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Qwen2-based embeddings. 8K+ sequence length. Multilingual."
  },
  {
    "id": "nomic-embed",
    "name": "Nomic Embed v1.5",
    "provider": "Nomic AI",
    "type": "Embedding",
    "family": "Nomic",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 0.14,
    "contextK": 8,
    "minVramGb": 1,
    "recommendedVramGb": 2,
    "minRamGb": 2,
    "recommendedRamGb": 4,
    "notes": "Fully open embedding. Matryoshka + binary quantization. Fast."
  },
  {
    "id": "jina-embed-v3",
    "name": "Jina Embeddings v3",
    "provider": "Jina AI",
    "type": "Embedding",
    "family": "Jina",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES", "JA"],
    "license": "Apache-2.0",
    "paramsB": 0.57,
    "contextK": 8,
    "minVramGb": 1,
    "recommendedVramGb": 2,
    "minRamGb": 4,
    "recommendedRamGb": 8,
    "notes": "Task-specific LoRA adapters. Multilingual with Arabic support."
  },

  {
    "id": "cogvideox",
    "name": "CogVideoX",
    "provider": "Zhipu AI",
    "type": "Video Gen",
    "family": "CogVideo",
    "open": true,
    "moe": false,
    "modalities": ["Video"],
    "languages": ["EN", "ZH"],
    "license": "Apache-2.0",
    "paramsB": null,
    "contextK": null,
    "minVramGb": 16,
    "recommendedVramGb": 24,
    "minRamGb": 32,
    "recommendedRamGb": 48,
    "notes": "Open text-to-video. 6-second clips. 3D VAE architecture."
  },

  {
    "id": "hunyuan-video",
    "name": "HunyuanVideo",
    "provider": "Tencent",
    "type": "Video Gen",
    "family": "Hunyuan",
    "open": true,
    "moe": false,
    "modalities": ["Video"],
    "languages": ["EN", "ZH"],
    "license": "Tencent Hunyuan",
    "paramsB": 13,
    "contextK": null,
    "minVramGb": 24,
    "recommendedVramGb": 48,
    "minRamGb": 48,
    "recommendedRamGb": 80,
    "notes": "Open text-to-video. Dual-stream DiT. High quality motion."
  },

  {
    "id": "mochi-1",
    "name": "Mochi 1",
    "provider": "Genmo",
    "type": "Video Gen",
    "family": "Mochi",
    "open": true,
    "moe": false,
    "modalities": ["Video"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 10,
    "contextK": null,
    "minVramGb": 24,
    "recommendedVramGb": 48,
    "minRamGb": 48,
    "recommendedRamGb": 80,
    "notes": "Open video gen with asymmetric diffusion transformer."
  },

  {
    "id": "runway-gen3",
    "name": "Runway Gen-3 Alpha",
    "provider": "Runway",
    "type": "Video Gen",
    "family": "Gen",
    "open": false,
    "moe": false,
    "modalities": ["Video"],
    "languages": ["EN"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": null,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Text/image to video. High-fidelity motion. Cloud-only."
  },

  {
    "id": "pika",
    "name": "Pika",
    "provider": "Pika Labs",
    "type": "Video Gen",
    "family": "Pika",
    "open": false,
    "moe": false,
    "modalities": ["Video"],
    "languages": ["EN"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": null,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Text/image to video. Creative video generation. Cloud-only."
  },

  {
    "id": "kling",
    "name": "Kling",
    "provider": "Kuaishou",
    "type": "Video Gen",
    "family": "Kling",
    "open": false,
    "moe": false,
    "modalities": ["Video"],
    "languages": ["EN", "ZH"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": null,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Text-to-video. Up to 2 minutes. Cinematic quality. Cloud-only."
  },

  {
    "id": "midjourney",
    "name": "Midjourney",
    "provider": "Midjourney",
    "type": "Image Gen",
    "family": "Midjourney",
    "open": false,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": null,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Leading image generation service. Artistic quality. Cloud via Discord."
  },

  {
    "id": "ideogram-2",
    "name": "Ideogram 2",
    "provider": "Ideogram",
    "type": "Image Gen",
    "family": "Ideogram",
    "open": false,
    "moe": false,
    "modalities": ["Image"],
    "languages": ["EN"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": null,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Best text rendering in images. Great for logos and typography."
  },

  {
    "id": "nous-hermes-2-mixtral",
    "name": "Nous Hermes 2 Mixtral 8x7B",
    "provider": "Nous Research",
    "type": "LLM",
    "family": "Hermes",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Apache-2.0",
    "paramsB": 47,
    "contextK": 32,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "Fine-tuned Mixtral. Strong instruction following and function calling."
  },

  {
    "id": "wizardcoder-33b",
    "name": "WizardCoder 33B",
    "provider": "WizardLM",
    "type": "Code LLM",
    "family": "WizardCoder",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN"],
    "license": "Meta",
    "paramsB": 33,
    "contextK": 16,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "Fine-tuned Code Llama with Evol-Instruct. Strong coding."
  },

  {
    "id": "reka-core",
    "name": "Reka Core",
    "provider": "Reka",
    "type": "LLM",
    "family": "Reka",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "ZH"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Multimodal (text, image, video, audio). Cloud-only."
  },
  {
    "id": "reka-flash",
    "name": "Reka Flash",
    "provider": "Reka",
    "type": "LLM",
    "family": "Reka",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN"],
    "license": "Commercial",
    "paramsB": 21,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Fast multimodal model. Good balance of speed and quality."
  },

  {
    "id": "kimi",
    "name": "Kimi",
    "provider": "Moonshot AI",
    "type": "LLM",
    "family": "Kimi",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 2000,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "2M token context window. Excellent for long document analysis."
  },

  {
    "id": "minimax-01",
    "name": "MiniMax-01",
    "provider": "MiniMax",
    "type": "LLM",
    "family": "MiniMax",
    "open": true,
    "moe": true,
    "modalities": ["Text"],
    "languages": ["EN", "ZH"],
    "license": "MiniMax Open",
    "paramsB": 456,
    "contextK": 4000,
    "minVramGb": 80,
    "recommendedVramGb": 160,
    "minRamGb": 256,
    "recommendedRamGb": 512,
    "notes": "MoE with 4M context. Lightning attention. Hybrid architecture."
  },

  {
    "id": "ernie-4",
    "name": "ERNIE 4.0",
    "provider": "Baidu",
    "type": "LLM",
    "family": "ERNIE",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "ZH"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Baidu's flagship model. Chinese language excellence. Cloud-only."
  },

  {
    "id": "doubao",
    "name": "Doubao",
    "provider": "ByteDance",
    "type": "LLM",
    "family": "Doubao",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "ZH"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "ByteDance's AI model. Powers TikTok AI features. Cloud-only."
  },

  {
    "id": "spark",
    "name": "Spark",
    "provider": "iFlytek",
    "type": "LLM",
    "family": "Spark",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "ZH"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Chinese AI assistant. Strong in speech and NLP. Cloud-only."
  },

  {
    "id": "amazon-nova-pro",
    "name": "Amazon Nova Pro",
    "provider": "Amazon",
    "type": "LLM",
    "family": "Nova",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 300,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Multimodal model via AWS Bedrock. 300K context. Cloud-only."
  },
  {
    "id": "amazon-nova-lite",
    "name": "Amazon Nova Lite",
    "provider": "Amazon",
    "type": "LLM",
    "family": "Nova",
    "open": false,
    "moe": false,
    "modalities": ["Multi"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 300,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Cost-effective multimodal. Fast inference. Cloud via Bedrock."
  },
  {
    "id": "amazon-nova-micro",
    "name": "Amazon Nova Micro",
    "provider": "Amazon",
    "type": "LLM",
    "family": "Nova",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["EN", "AR", "ZH", "FR", "DE", "ES"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": 128,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Ultra-low latency text model. Cheapest Nova variant."
  },

  {
    "id": "jais-30b",
    "name": "Jais 30B",
    "provider": "Inception (G42)",
    "type": "LLM",
    "family": "Jais",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["AR", "EN"],
    "license": "Apache-2.0",
    "paramsB": 30,
    "contextK": 8,
    "minVramGb": 18,
    "recommendedVramGb": 24,
    "minRamGb": 48,
    "recommendedRamGb": 64,
    "notes": "Arabic-first LLM from UAE. Best open Arabic language model."
  },
  {
    "id": "jais-70b",
    "name": "Jais 70B",
    "provider": "Inception (G42)",
    "type": "LLM",
    "family": "Jais",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["AR", "EN"],
    "license": "Apache-2.0",
    "paramsB": 70,
    "contextK": 8,
    "minVramGb": 40,
    "recommendedVramGb": 80,
    "minRamGb": 96,
    "recommendedRamGb": 160,
    "notes": "Largest Arabic-first model. State-of-the-art Arabic NLP."
  },

  {
    "id": "allam",
    "name": "ALLaM",
    "provider": "SDAIA",
    "type": "LLM",
    "family": "ALLaM",
    "open": false,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["AR", "EN"],
    "license": "Commercial",
    "paramsB": null,
    "contextK": null,
    "minVramGb": null,
    "recommendedVramGb": null,
    "minRamGb": null,
    "recommendedRamGb": null,
    "notes": "Saudi Arabic LLM. Developed by SDAIA. Arabic language specialist."
  },

  {
    "id": "acegpt",
    "name": "AceGPT 13B",
    "provider": "MBZUAI",
    "type": "LLM",
    "family": "AceGPT",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["AR", "EN"],
    "license": "Apache-2.0",
    "paramsB": 13,
    "contextK": 4,
    "minVramGb": 8,
    "recommendedVramGb": 12,
    "minRamGb": 24,
    "recommendedRamGb": 32,
    "notes": "Arabic-tuned Llama. From Mohamed bin Zayed University of AI."
  },

  {
    "id": "silma-9b",
    "name": "Silma 9B",
    "provider": "Silma AI",
    "type": "LLM",
    "family": "Silma",
    "open": true,
    "moe": false,
    "modalities": ["Text"],
    "languages": ["AR", "EN"],
    "license": "Apache-2.0",
    "paramsB": 9,
    "contextK": 32,
    "minVramGb": 5,
    "recommendedVramGb": 10,
    "minRamGb": 16,
    "recommendedRamGb": 24,
    "notes": "Arabic-focused open model. Fine-tuned for Arabic NLP tasks."
  }
]
